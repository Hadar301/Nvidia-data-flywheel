# Custom values for deploying Data Flywheel to OpenShift cluster
# Uses existing NeMo Microservices infrastructure already deployed in hacohen-flywheel namespace

namespace: "hacohen-flywheel"

# Deployment profile settings
profile:
  production:
    enabled: false    # Enable Flower for debugging
  mlflow:
    COMPOSE_PROFILES: "mlflow"

# Image pull secrets - using your NGC API key
imagePullSecrets:
  - name: nvcrimagepullsecret
    registry: nvcr.io
    username: $oauthtoken
    password: ""  # Set via --set during install

# Secret configurations
secrets:
  ngcApiKey: ""       # Set via --set secrets.ngcApiKey=$NGC_API_KEY
  nvidiaApiKey: ""    # Set via --set secrets.nvidiaApiKey=$NVIDIA_API_KEY
  hfToken: ""         # Set via --set secrets.hfToken=$HF_TOKEN
  llmJudgeApiKey: ""  # Set via --set secrets.llmJudgeApiKey=$LLM_JUDGE_API_KEY
  embApiKey: ""       # Set via --set secrets.embApiKey=$EMB_API_KEY

# Disable Elasticsearch - using existing elasticsearch-master
elasticsearch:
  enabled: false

# Disable MongoDB - using existing flywheel-infra-mongodb
mongodb:
  enabled: false

# Disable Redis - using existing flywheel-infra-redis-master
redis:
  enabled: false

# Kibana - disabled (not required for Data Flywheel)
kibana:
  enabled: false

# Data Flywheel server configuration
foundationalFlywheelServer:
  image:
    repository: nvcr.io/nvidia/blueprint/foundational-flywheel-server
    tag: "0.3.0"
  imagePullSecrets:
    - name: nvcrimagepullsecret

  deployments:
    api:
      enabled: true
      fullnameOverride: "df-api"
      service:
        type: ClusterIP
        port: 8000
      env:
        # Use existing Elasticsearch (HTTP, no auth)
        ELASTICSEARCH_URL: "http://elasticsearch-master:9200"
        # Use existing Redis
        REDIS_URL: "redis://flywheel-infra-redis-master:6379/0"
        # Use existing MongoDB
        MONGODB_URL: "mongodb://flywheel-infra-mongodb:27017"
        MONGODB_DB: "flywheel"
        ES_COLLECTION_NAME: "flywheel"
        # Set HOME to writable directory for OpenShift
        HOME: "/tmp"
      resources:
        requests:
          memory: "1Gi"
          cpu: "1"
          ephemeral-storage: "10Gi"
        limits:
          memory: "2Gi"
          cpu: "2"
          ephemeral-storage: "20Gi"
      command:
        - "uv"
        - "run"
        - "uvicorn"
        - "src.app:app"
        - "--host"
        - "0.0.0.0"
        - "--port"
        - "8000"

    celeryWorker:
      enabled: true
      fullnameOverride: "df-celery-worker"
      env:
        ELASTICSEARCH_URL: "http://elasticsearch-master:9200"
        REDIS_URL: "redis://flywheel-infra-redis-master:6379/0"
        MONGODB_URL: "mongodb://flywheel-infra-mongodb:27017"
        MONGODB_DB: "flywheel"
        ES_COLLECTION_NAME: "flywheel"
        HOME: "/tmp"
      resources:
        requests:
          memory: "10Gi"
          cpu: "4"
          ephemeral-storage: "10Gi"
        limits:
          memory: "20Gi"
          cpu: "8"
          ephemeral-storage: "20Gi"
      command:
        - "uv"
        - "run"
        - "celery"
        - "-A"
        - "src.tasks.cli:celery_app"
        - "worker"
        - "--loglevel=info"
        - "--concurrency=50"
        - "--queues=celery"
        - "-n"
        - "main_worker@%h"
        - "--purge"

    celeryParentWorker:
      enabled: true
      fullnameOverride: "df-celery-parent-worker"
      env:
        ELASTICSEARCH_URL: "http://elasticsearch-master:9200"
        REDIS_URL: "redis://flywheel-infra-redis-master:6379/0"
        MONGODB_URL: "mongodb://flywheel-infra-mongodb:27017"
        MONGODB_DB: "flywheel"
        ES_COLLECTION_NAME: "flywheel"
        HOME: "/tmp"
      resources:
        requests:
          memory: "1Gi"
          cpu: "1"
          ephemeral-storage: "10Gi"
        limits:
          memory: "2Gi"
          cpu: "2"
          ephemeral-storage: "20Gi"
      command:
        - "uv"
        - "run"
        - "celery"
        - "-A"
        - "src.tasks.cli:celery_app"
        - "worker"
        - "--loglevel=info"
        - "--concurrency=1"
        - "--queues=parent_queue"
        - "-n"
        - "parent_worker@%h"
        - "--purge"

    mlflow:
      fullnameOverride: "df-mlflow"
      image: ghcr.io/mlflow/mlflow:v2.22.0
      service:
        type: ClusterIP
        port: 5000
      resources:
        requests:
          memory: "1Gi"
          cpu: "500m"
          ephemeral-storage: "2Gi"
        limits:
          memory: "2Gi"
          cpu: "2"
          ephemeral-storage: "5Gi"
      command:
        - "mlflow"
        - "server"
        - "--host"
        - "0.0.0.0"
        - "--port"
        - "5000"

    flower:
      fullnameOverride: "df-flower"
      service:
        type: ClusterIP
        port: 5555
      env:
        ELASTICSEARCH_URL: "http://elasticsearch-master:9200"
        REDIS_URL: "redis://flywheel-infra-redis-master:6379/0"
        MONGODB_URL: "mongodb://flywheel-infra-mongodb:27017"
        MONGODB_DB: "flywheel"
        ES_COLLECTION_NAME: "flywheel"
        HOME: "/tmp"
      resources:
        requests:
          memory: "1Gi"
          cpu: "1"
          ephemeral-storage: "2Gi"
        limits:
          memory: "2Gi"
          cpu: "2"
          ephemeral-storage: "5Gi"
      command:
        - "uv"
        - "run"
        - "celery"
        - "-A"
        - "src.tasks.tasks"
        - "flower"
        - "--port=5555"

  # Configuration for Data Flywheel - using existing NeMo services
  config:
    nmp_config:
      # Use existing nemo-gateway service (internal cluster DNS)
      nemo_base_url: "http://nemo-gateway"
      # Use existing NIM service
      nim_base_url: "http://meta-llama3-1b-instruct:8000"
      # Datastore also goes through gateway
      datastore_base_url: "http://nemo-gateway"
      # Your namespace
      nmp_namespace: "hacohen-flywheel"

    logging_config:
      level: "INFO"

    mlflow_config:
      tracking_uri: "http://df-mlflow-service:5000"
      experiment_name_prefix: "data-flywheel"
      artifact_location: "./mlruns"

    # Use remote LLM judge to save cluster resources
    llm_judge_config:
      deployment_type: "remote"
      url: "https://integrate.api.nvidia.com/v1/chat/completions"
      model_name: "meta/llama-3.3-70b-instruct"

    # Reference existing NIM - mark as already deployed
    nims:
      - model_name: "meta/llama-3.2-1b-instruct"
        model_type: "llm"
        context_length: 8192
        gpus: 1
        pvc_size: 25Gi
        tag: "1.8.3"
        customization_enabled: true
        customizer_configs:
          target: "meta/llama-3.2-1b-instruct@2.0"
          gpus: 1
          max_seq_length: 8192

    data_split_config:
      eval_size: 100
      val_ratio: 0.1
      min_total_records: 50
      random_seed: null
      limit: 1000
      parse_function_arguments: true

    icl_config:
      max_context_length: 32768
      reserved_tokens: 4096
      max_examples: 3
      min_examples: 1
      example_selection: "semantic_similarity"
      similarity_config:
        relevance_ratio: 0.7
        embedding_nim_config:
          # Use remote embedding service
          deployment_type: "remote"
          url: "https://integrate.api.nvidia.com/v1/embeddings"
          model_name: "nvidia/llama-3.2-nv-embedqa-1b-v2"

    training_config:
      training_type: "sft"
      finetuning_type: "lora"
      epochs: 2
      batch_size: 16
      learning_rate: 0.0001

    lora_config:
      adapter_dim: 32
      adapter_dropout: 0.1

# Disable NeMo Microservices sub-chart - we're using existing infrastructure
nemo-microservices-helm-chart:
  enabled: false
